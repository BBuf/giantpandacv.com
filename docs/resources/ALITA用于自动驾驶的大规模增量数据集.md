# ALITA:用于自动驾驶的大规模增量数据集

## **0. 引言**

位置识别与闭环检测是自动驾驶系统中的关键任务，但现有方法基本都是在特定场景下进行评估，这样很难评价现有方法在大规模、长期、变视角环境下的准确性、鲁棒性和泛化能力，即很难判断其在实际应用中的性能。而收集符合要求的实际大规模场景数据集需要复杂、昂贵以及能够长期运行的采集平台，本文将为大家分享一个用于自动驾驶的大规模增量数据集，该数据集可以用于实际场景的性能评估。数据集，以及用于数据处理和本地评估的Python-API已经开源。

## **1. 论文信息**

标题：ALITA: A Large-scale Incremental Dataset for Long-term Autonomy

作者：Peng Yin, Shiqi Zhao, Ruohai Ge, Ivan Cisneros, Ruijie Fu, Ji Zhang, Howie Choset, Sebastian Scherer

来源：2022 Robotics

原文链接：https://arxiv.org/abs/2205.10737

数据集链接：https://github.com/MetaSLAM/ALITA

## **2. 摘要**

对于长期自动驾驶，大多数位置识别方法主要是在简化场景或模拟数据集上进行评估，这不能为评估当前同时定位和地图创建(SLAM)的就绪性提供坚实的证据。在本文中，我们提出了一个长期位置识别数据集，用于大规模动态环境下的移动定位。该数据集包括一个校园尺度的轨迹和一个城市尺度的轨迹:1)校园轨迹关注长期属性，我们在10个轨迹上记录激光雷达设备和全景相机，每个轨迹在不同照明条件下重复记录8次。2)城市轨道聚焦于大范围的属性，我们将激光雷达设备安装在车辆上，穿越120公里的轨迹，包括开放的街道、居民区、自然地形等。它们包括200小时的城市环境中各种场景的原始数据。在每个轨迹上提供两个轨迹的地面真实位置，这是从全球定位系统获得的，具有附加的基于一般ICP的点云细化。为了简化评估过程，我们还使用Python-API提供了一组地点识别指标，用于快速加载数据集并评估不同方法的识别性能。该数据集旨在寻找具有高位置识别准确性和鲁棒性的方法，并为真正的机器人系统提供长期自主性。

## **3. 数据集分析**

作者提出了一个用于大规模环境下长期位置识别的数据集iData，数据集的目标是长期定位这一挑战任务，该数据集包含两个轨迹分支：

\(1\) 城市数据集，它记录了城市尺度中总共50条车辆轨迹和120公里轨迹的激光雷达数据输入，每个轨迹至少在一个交叉点与其他轨迹重叠，并且在数据集中有158个重叠。采集地点位于宾夕法尼亚州匹兹堡市。

\(2\) 校园数据集，分别在不同的照明和视点下，在10个不同的轨迹上收集了8次重复的全景视觉输入和激光雷达输入，全长约36公里。采集地点位于卡耐基梅隆大学(CMU)校园区域。

图1所示是数据集的可视化结果，表1所示是不同数据集的比较结果。

![](https://img-blog.csdnimg.cn/d8381c8b13004f9b8ba1023b2ff65024.png)

图1 iDATA数据集

包括使用Velodyne-16和Xsens MTI-300 IMU采集的城市和校园数据集。城市数据集包含5个区域 (以绿色、黄色、红色、纱色和蓝色着色)，涵盖街区、住宅区、公园和商业建筑。校园数据集以紫色显示，涵盖了卡内基梅隆大学的主校区



表1 不同地图合并方法的比较

P-Cam代表针孔摄像机，360Cam代表全景摄像机。Temporal表示数据记录的时间窗口，Perspective表示视点是固定还是变化

![](https://img-blog.csdnimg.cn/ed34df3d472d4b7296c98e1379d2211f.png)

大多数数据集都是针对短期、固定条件或视点位置识别任务，难以评估在现实世界中长期、大规模应用中的定位性能。与现有数据集相比，作者提出的城市数据集覆盖了大规模变化的3D场景，并且可以应用于不同视点差异下的评估，涵盖了长期动态对象、照明和视点差异。作者提出的城市和校园数据集都为准确的位置识别提供了事实依据，有助于对不同方法进行评估。此外，该城市数据集已在ICRA 2022中使用General Place Recognition Competition对当前新的3D位置识别方法进行基准测试。

## **4. 采集平台**

### 4.1 硬件设置

作者的数据采集平台包含一台Velodyne-16激光雷达扫描仪、Xsens MTI-300惯性测量单元和一台Nvidia Jetson TX2板载计算机。对于城市数据集，作者将平台安装在移动车辆的顶部，并与GNSS定位系统同步运行，以记录城市规模环境的地面真实位置。如图2所示是作者用于校园数据集采集的平台，基础平台与城市数据集相同。此外，作者在激光雷达设备的顶部安装额外的全景相机和实感VIO设备(T265)，进而提供时间同步的激光雷达输入和360°全景视觉输入。

![](https://img-blog.csdnimg.cn/0b98dfc643f94f6faea834939b2ef40c.png)

图2 数据采集平台

### 4.2 数据集格式

作者提出的城市数据集由4种类型的数据组成，主要描述如下：

\(1\) 全局地图：全局地图被处理以包含以点云数据(PCD)文件格式提供的每个轨迹的3D结构。

\(2\) 轨迹：每个轨迹主要通过LOAM生成并通过交互式SLAM进行优化，文件格式为TXT。

\(3\) 子地图：每个全局地图沿着对应的轨迹分成若干子地图，一个子地图的大小为50m\*50m，每两个子地图之间的距离约为2m。子地图数据以点云数据(PCD)文件格式提供。

\(4\) 真实位姿：对于每个子地图，相应的真实位姿包含位置和姿态信息。作者使用NumPy进行数据处理，并以标准二进制(NPY)文件格式提供。



作者提出的校园数据集由4种类型的数据组成，主要描述如下:

\(1\) 全局地图：全局地图被处理以包含以点云数据(PCD)文件格式提供的每个轨迹的3D结构。

\(2\) 里程计：里程计由壤LOAM生成并以TXT文件格式提供。

\(3\) 相对里程计：相对里程计由交互式SLAM处理，以生成其他序列相对于参考序列的相对位置。该数据以TXT文件格式提供。

\(4\) 全景图片：对于里程计中的每一帧位姿，相应的全景图片以PNG文件格式提供。

## **5. 总结**

在2022 Robotics 论文"ALITA: A Large-scale Incremental Dataset for Long-term Autonomy"中，作者提出了iDATA数据集，旨在实现大规模环境下的长期位置识别任务。该数据集将有助于处理光照和视点变化的位置识别研究，以及基于激光雷达图像(全景)融合的机器人研究。此外，由于提出的iDATA数据集在轨迹之间提供了丰富的重叠，该数据集也可用于地图合并系统。
