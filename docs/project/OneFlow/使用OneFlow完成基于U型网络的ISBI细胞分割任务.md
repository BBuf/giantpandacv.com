```python
æ–‡ç« ç›®å½•
1. Introduction
2. ç½‘è·¯æ¶æ„
3. æ•°æ®å’Œç¨‹åºå‡†å¤‡
4. ä½¿ç”¨æ­¥éª¤
5. å•æœºå•å¡è®­ç»ƒæ–¹å¼
6. å•æœºå¤šå¡è®­ç»ƒæ–¹å¼(DDP)
7. å¯è§†åŒ–å®éªŒç»“æœ
8. Conclusion and discussion
```

# 1. Introduction

æœ¬æ–‡åŸºäºOneFlowå’ŒU-Netå®ç°ISBIæŒ‘æˆ˜èµ›çš„ç»†èƒåˆ†å‰²ï¼Œä»£ç åŒ…æ‹¬å•æœºå•å¡å’Œå•æœºå¤šå¡ä¸¤ç§è®­ç»ƒæ–¹å¼ï¼ŒOneFlow æä¾›äº† `oneflow.nn.parallel.DistributedDataParallel` æ¨¡å—åŠ `launcher`ï¼Œå¯ä»¥å‡ ä¹ä¸ç”¨å¯¹å•æœºå•å¡è„šæœ¬åšä¿®æ”¹ï¼Œå°±èƒ½åœ°è¿›è¡Œ**æ•°æ®å¹¶è¡Œ**è®­ç»ƒã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå› ä¸ºæˆ‘ç›®å‰åœ¨OneFlowåšä¸€åç®—æ³•å®ä¹ ç”Ÿï¼Œæœ¬æ–‡æ›´å¤šä»¥ä¸€ä¸ªåˆæ¬¡æ¥è§¦OneFlowæ¡†æ¶çš„ç”¨æˆ·è§’åº¦è¿›è¡Œåˆ†æï¼ŒåŒ…æ‹¬APIã€åˆ†å¸ƒå¼è®­ç»ƒèƒ½åŠ›ã€é«˜æ€§èƒ½å’Œæˆ‘çš„ä¸€äº›å®ä¹ æ„Ÿå—(ä¸é‡è¦ğŸ‘€)ã€‚

ISBIç»†èƒåˆ†å‰²ä»»åŠ¡ï¼šç»™ä¸€å¼ ç»†èƒç»“æ„å›¾ï¼Œå¯¹è¾¹ç¼˜è½®å»“è¿›è¡ŒäºŒåˆ†ç±»ï¼Œå¦‚ä¸‹åŠ¨å›¾æ‰€ç¤ºã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/img_convert/cfcf37912abcc0d6b3ddddf4c004f597.gif#pic_center)

è®­ç»ƒæ•°æ®æœ‰30å¼ ï¼Œåˆ†è¾¨ç‡ä¸º`512x512`ï¼Œè¿™äº›å›¾ç‰‡æ˜¯æœè‡çš„ç”µé•œç»†èƒå›¾ã€‚


#  2. ç½‘è·¯æ¶æ„

U-Netç½‘ç»œæ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å®ƒç”±ä¸€ä¸ªæ”¶ç¼©è·¯å¾„å’Œä¸€ä¸ªæ‰©å±•è·¯å¾„ç»„æˆã€‚æ”¶ç¼©è·¯å¾„éµå¾ªå·ç§¯ç½‘ç»œçš„å…¸å‹æ¶æ„ã€‚å®ƒåŒ…æ‹¬é‡å¤ä½¿ç”¨ä¸¤ä¸ª 3x3 å·ç§¯ï¼Œæ¯ä¸ªå·ç§¯åè·Ÿä¸€ä¸ªçº¿æ€§ä¿®æ­£å•å…ƒ(ReLU)å’Œä¸€ä¸ª2x2æœ€å¤§æ± åŒ–æ“ä½œï¼Œæ­¥é•¿ä¸º2çš„ä¸‹é‡‡æ ·ã€‚åœ¨æ¯ä¸ªä¸‹é‡‡æ ·æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†ç‰¹å¾é€šé“çš„æ•°é‡åŠ å€ã€‚æ‰©å±•è·¯å¾„ä¸­çš„æ¯ä¸€æ­¥éƒ½åŒ…æ‹¬ç‰¹å¾æ˜ å°„çš„ä¸Šé‡‡æ ·ï¼Œç„¶åè¿›è¡Œ 2x2 å‘ä¸Šå·ç§¯ï¼Œå°†ç‰¹å¾é€šé“æ•°é‡å‡åŠï¼Œä¸æ¥è‡ªæ”¶ç¼©è·¯å¾„çš„ç›¸åº”è£å‰ªç‰¹å¾æ˜ å°„ä¸²è”ã€‚ç„¶åæ˜¯ä¸¤ä¸ª3x3å·ç§¯ï¼Œæ¯ä¸ªå·ç§¯åé¢æ¥ReLUã€‚ç”±äºæ¯ä¸€æ¬¡å·ç§¯éƒ½ä¼šä¸¢å¤±è¾¹ç•Œåƒç´ ï¼Œå› æ­¤è£å‰ªæ˜¯å¿…è¦çš„ã€‚åœ¨æœ€åä¸€å±‚ï¼Œä½¿ç”¨1x1å·ç§¯å°†æ¯ä¸ªåˆ†é‡ç‰¹å¾å‘é‡æ˜ å°„åˆ°æ‰€éœ€æ•°é‡çš„ç±»åˆ«(2ç±»)ä¸Šã€‚ç½‘ç»œæ€»å…±æœ‰23ä¸ªå·ç§¯å±‚ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/44997ebd4f0f40dfb7875d18f7dd97ce.png?x-oss-process=imagetype_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASWRlYWxDVg==,size_20,color_FFFFFF,t_70,g_se,x_16)

æ ¹æ®ä¸Šé¢çš„ç½‘ç»œç»“æ„ï¼Œä½¿ç”¨OneFlowå®ç°Uå‹ç½‘ç»œç»“æ„ä»£ç å¦‚ä¸‹ï¼š

```python
"""
Creates a U-Net Model as defined in:
U-Net: Convolutional Networks for Biomedical Image Segmentation
https://arxiv.org/abs/1505.04597
Modified from https://github.com/milesial/Pytorch-UNet
"""
import oneflow as flow
import oneflow.nn as nn
import oneflow.nn.functional as F


class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2), DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """Upscaling then double conv"""

    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        # if bilinear, use the normal convolutions to reduce the number of channels
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=True)
        else:
            self.up = nn.ConvTranspose2d(
                in_channels, out_channels, kernel_size=2, stride=2
            )

        self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # input is CHW
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))

        x = flow.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)


class UNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        self.down4 = Down(512, 1024)
        self.up1 = Up(1024, 512, bilinear)
        self.up2 = Up(512, 256, bilinear)
        self.up3 = Up(256, 128, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return logits
```

# 3. æ•°æ®å’Œç¨‹åºå‡†å¤‡

åŸå§‹æ•°æ®ï¼šé¦–å…ˆå‡†å¤‡æ•°æ®ï¼Œå‚è€ƒæ•°æ®æ¥è‡ªäº ISBI æŒ‘æˆ˜çš„æ•°æ®é›†ã€‚æ•°æ®å¯ä»¥åœ¨æœ¬ä»“åº“(https://github.com/Oneflow-Inc/models/tree/main/Vision/segmentation/U-Net)ä¸‹è½½åˆ°ï¼Œå«30å¼ è®­ç»ƒå›¾ã€30å¼ å¯¹åº”çš„æ ‡ç­¾ã€‚30å¼ æµ‹è¯•å›¾ç‰‡ã€‚

å¢å¼ºåçš„æ•°æ® ï¼šè°·æ­Œäº‘ç›˜(https://drive.google.com/drive/folders/0BzWLLyI3R0pLclMzMzRxUm1qZmc)

ä»¥ä¸Šæ•°æ®äºŒé€‰ä¸€ã€‚

ä»£ç é“¾æ¥: https://github.com/Oneflow-Inc/models/tree/main/Vision/segmentation/U-Net

è¯¥ç¨‹åºç›®å½•å¦‚ä¸‹ï¼š

```
dataloader.py//åŠ è½½æ•°æ®
plot.py//ç»˜åˆ¶lossæ›²çº¿
TrainUnetDataSet.py//è®­ç»ƒæ–‡ä»¶
unet.py//ç½‘è·¯ç»“æ„
predict_unet_test.py//æµ‹è¯•æ–‡ä»¶
tran.sh//è®­ç»ƒè„šæœ¬
test.sh//æµ‹è¯•è„šæœ¬
```

# 4. ä½¿ç”¨æ­¥éª¤

è®­ç»ƒï¼š

```shell
bash train.sh
```

æµ‹è¯•ï¼š

```shell
bash test.sh
```

# 5. å•æœºå•å¡è®­ç»ƒæ–¹å¼

åœ¨`TrainUnetDataSet.py`ä¸­ï¼Œä¸ºäº†ä¸å•æœºå¤šå¡è®­ç»ƒæ–¹å¼å¯¹æ¯”ï¼Œè¿™é‡Œç»™å‡ºè®­ç»ƒU-Netçš„å®Œæ•´è„šæœ¬ï¼Œå¦‚ä¸‹ï¼š

```python
def Train_Unet(net, device, data_path, batch_size=3, epochs=40, lr=0.0001):
    train_dataset = SelfDataSet(data_path)
    train_loader = utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True
    )

    opt = optim.Adam((net.parameters()))
    loss_fun = nn.BCEWithLogitsLoss()
    bes_los = float("inf")

    for epoch in range(epochs):
        net.train()
        running_loss = 0.0
        i = 0
        begin = time.perf_counter()
        for image, label in train_loader:
            opt.zero_grad()
            image = image.to(device=device, dtype=flow.float32)
            label = label.to(device=device, dtype=flow.float32)
            pred = net(image)
            loss = loss_fun(pred, label)
            loss.backward()
            i = i + 1
            running_loss = running_loss + loss.item()
            opt.step()
        end = time.perf_counter()
        loss_avg_epoch = running_loss / i
        Unet_train_txt.write(str(format(loss_avg_epoch, ".4f")) + "\n")
        print("epoch: %d avg loss: %f time:%d s" % (epoch, loss_avg_epoch, end - begin))
        if loss_avg_epoch < bes_los:
            bes_los = loss_avg_epoch
            state = {"net": net.state_dict(), "opt": opt.state_dict(), "epoch": epoch}
            flow.save(state, "./checkpoints")

def main(args):
    DEVICE = "cuda" if flow.cuda.is_available() else "cpu"
    print("Using {} device".format(DEVICE))
    net = UNet(1, 1, bilinear=False)
    # print(net)
    net.to(device=DEVICE)
    data_path = args.data_path
    Train_Unet(net, DEVICE, data_path, epochs=args.epochs, batch_size=args.batch_size)
    Unet_train_txt.close()
```

# 6. å•æœºå¤šå¡è®­ç»ƒæ–¹å¼(DDP)

OneFlow æä¾›äº† `oneflow.nn.parallel.DistributedDataParallel` æ¨¡å—åŠ `launcher`ï¼Œå¯ä»¥å‡ ä¹ä¸ç”¨å¯¹å•æœºå•å¡è„šæœ¬åšä¿®æ”¹ï¼Œå°±èƒ½åœ°è¿›è¡Œ**DDP**è®­ç»ƒã€‚

æ ¹æ®è¯¥ç‰¹æ€§ï¼Œæ•°æ®å¹¶è¡Œçš„è®­ç»ƒä»£ç ä¸å•æœºå•å¡è„šæœ¬çš„ä¸åŒåªæœ‰2ä¸ªï¼Œå°†ç¬¬5èŠ‚çš„è®­ç»ƒè„šæœ¬åšå¦‚ä¸‹ä¿®æ”¹ï¼š

1. ä½¿ç”¨ `DistributedDataParallel` å¤„ç†ä¸€ä¸‹ module å¯¹è±¡

```python
    m=net.to(device=DEVICE)
    net = ddp(m)
```

2. ä½¿ç”¨`DistributedSampler`åœ¨æ¯ä¸ªè¿›ç¨‹ä¸­å®ä¾‹åŒ–`Dataloader`ï¼Œæ¯ä¸ª`Dataloader`å®ä¾‹åŠ è½½å®Œæ•´æ•°æ®çš„ä¸€éƒ¨åˆ†ï¼Œè‡ªåŠ¨å®Œæˆæ•°æ®çš„åˆ†å‘ã€‚

```python
    is_distributed=True
    sampler = flow.utils.data.distributed.DistributedSampler(train_dataset) if is_distributed else None
    train_loader = utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=(sampler is None), sampler=sampler
    )
```

åœ¨åˆ†å¸ƒå¼æ¨¡å¼ä¸‹ï¼Œåœ¨åˆ›å»ºDataLoaderè¿­ä»£å™¨ä¹‹å‰ï¼Œåœ¨æ¯ä¸ªepochå¼€å§‹æ—¶è°ƒç”¨set_epoch()æ–¹æ³•ï¼Œè¿™å¯¹äºåœ¨å¤šä¸ªepochä¸­æ­£ç¡®åœ°è¿›è¡Œshuffleæ˜¯å¿…è¦çš„ã€‚å¦åˆ™ï¼Œå°†æ€»æ˜¯ä½¿ç”¨ç›¸åŒçš„é¡ºåºã€‚

```python
    for epoch in range(epochs):
        if is_distributed:
            sampler.set_epoch(epoch)
            Â·Â·Â·
```

è¿™æ ·å°±å®Œæˆäº†åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬çš„ç¼–å†™ï¼Œç„¶åä½¿ç”¨ `launcher` å¯åŠ¨è„šæœ¬ï¼ŒæŠŠå‰©ä¸‹çš„ä¸€åˆ‡éƒ½äº¤ç»™ OneFlowï¼Œè®©åˆ†å¸ƒå¼è®­ç»ƒU-Netï¼Œåƒå•æœºå•å¡è®­ç»ƒU-Netä¸€æ ·ç®€å•ã€‚


```python
python3 -m oneflow.distributed.launch --nproc_per_node 8 ./ddp_train.py
```

`--nproc_per_node`é€‰é¡¹è¡¨ç¤ºè°ƒç”¨çš„GPUç»“ç‚¹æ•°é‡ã€‚

# 7.  å¯è§†åŒ–å®éªŒç»“æœ

è¯¥å®éªŒåªè®­ç»ƒäº†40ä¸ªEpochï¼Œæå‡Epochæ•°é‡å¯æ˜¾è‘—æå‡æ¨¡å‹ç²¾åº¦ã€‚

åŸå›¾ï¼š

![åŸå§‹å¾…åˆ†å‰²å›¾ç‰‡](https://img-blog.csdnimg.cn/f711f29ed7334d738c49e9ae6c3ff236.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASWRlYWxDVg==,size_20,color_FFFFFF,t_70,g_se,x_16)

U-Neté¢„æµ‹å›¾ï¼š

![uneté¢„æµ‹å›¾å±•ç¤º](https://img-blog.csdnimg.cn/89bb4148684349e183d737dec33d5ccb.png?x-oss-process=image,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASWRlYWxDVg==,size_20,color_FFFFFF,t_70,g_se,x_16)

# 8. Conclusion and discussion

æœ¬æ–‡æ›´å¤šä»¥ä¸€ä¸ªåˆæ¬¡æ¥è§¦OneFlowæ¡†æ¶çš„ç”¨æˆ·è§’åº¦è¿›è¡Œåˆ†æï¼Œåœ¨ä½¿ç”¨OneFlowè®­ç»ƒU-Netç½‘ç»œçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘çœŸæ­£æ„Ÿå—åˆ°OneFlowå¯¹æ–°ç”¨æˆ·çš„å‹å¥½ã€‚ä¹‹å‰çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä¸»è¦ä½¿ç”¨Keraså’ŒTensorFlowï¼Œä½†ä½¿ç”¨OneFlowå´å¯ä»¥å¾ˆå¿«ä¸Šæ‰‹ã€‚å› ä¸ºOneFlowçš„Eageræ¨¡å¼ï¼Œä¸ PyTorch å¯¹é½ï¼Œè®©ç†Ÿæ‚‰PyTorchçš„ç”¨æˆ·å¯ä»¥é›¶æˆæœ¬ç›´æ¥ä¸Šæ‰‹ã€‚ è‡³äºGraphæ¨¡å¼ï¼Œç›®å‰æˆ‘è¿˜æ²¡æœ‰è¿›è¡Œå®è·µï¼Œä½†Graphä¹Ÿæ˜¯åŸºäºé¢å‘å¯¹è±¡çš„ç¼–ç¨‹é£æ ¼ï¼Œç†Ÿæ‚‰åŠ¨æ€å›¾å¼€å‘çš„ç”¨æˆ·ï¼Œåªéœ€è¦æ”¹å¾ˆå°‘é‡çš„ä»£ç ï¼Œå°±å¯ä»¥ä½¿ç”¨é«˜æ•ˆç‡çš„é™æ€å›¾ã€‚

é¦–å…ˆï¼ŒOneFlowæä¾›çš„APIåŸºæœ¬å¯ä»¥æ»¡è¶³æˆ‘çš„æ‰€æœ‰éœ€æ±‚ï¼Œåœ¨ä¸‹ä¸€ç‰ˆæœ¬ä¸­ä¹Ÿå°†æä¾›æ›´åŠ è¯¦ç»†çš„APIå¸®åŠ©æ–‡æ¡£å’Œæ›´ä¸°å¯Œã€å®Œå–„çš„ç®—å­é›†ï¼Œå¯¹æ¯”TensorFlowå¤æ‚å’Œå¤§å‹çš„æ–‡æ¡£ï¼Œæˆ‘è®¤ä¸ºOneflowæ›´å…·æœ‰æ˜“ç”¨æ€§ã€‚

æ­¤å¤–ï¼ŒOneFlowåœ¨å¤„ç†å¤§è§„æ¨¡æ¨¡å‹ä¸Šçš„æ€§èƒ½æ˜¯æœ€é‡è¦çš„ã€‚è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æ¨¡å‹è§„æ¨¡è¶Šæ¥è¶Šå¤§ï¼Œå¤šèŠ‚ç‚¹é›†ç¾¤è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œä»¥æå‡ç®—åŠ›çš„æ–¹æ³•è¢«OneFlowæ›´å¥½çš„è§£å†³äº†ã€‚è€Œä¸”ï¼Œåˆ†å¸ƒå¼è®­ç»ƒçš„ç®€å•æ“ä½œä¹Ÿæ›´èƒ½æ»¡è¶³æˆ‘çš„éœ€æ±‚ã€‚

æœ€åï¼Œæˆ‘æƒ³è¯´ä¸€ä¸‹æˆ‘åœ¨OneFlowçŸ­æš‚çš„å®ä¹ ä½“éªŒğŸ’ğŸ»ï¼Œ11æœˆä»½15å·å…¥èŒï¼Œåˆ°ç°åœ¨ä¸ºæ­¢å·²ç»è¿‡å»ä¸‰å‘¨äº†ã€‚åœ¨è¿™ä¸‰å‘¨é‡Œï¼Œæˆ‘é™¤äº†æ„Ÿå—åˆ°å›½äº§æ·±åº¦å­¦ä¹ æ¡†æ¶æ­£åœ¨å¼‚å†›çªèµ·ä¹‹å¤–ï¼Œåœ¨BBufæ™“é›¨å“¥çš„è¨€ä¼ èº«æ•™ä¸‹ï¼Œä¹Ÿæ„Ÿå—åˆ°OneFlowå›¢é˜Ÿçš„é«˜æ•ˆå¼€å‘æ–¹å¼ã€‚ä¸‰å‘¨çš„æ—¶é—´è¿‡çš„å¾ˆå¿«ï¼Œå¯¹æ¯”æˆ‘è‡ªå·±æ²¡æœ‰piplineå¼çš„å­¦ä¹ ï¼Œåœ¨OneFlowå­¦ä¹ å’Œå·¥ä½œç¡®å®å¯¹æˆ‘çš„ä¸ªäººæå‡å¾ˆæœ‰benefitsã€‚è¿™é‡ŒæŠ“é‡ç‚¹äº†ğŸ‘€ï¼Œå®ä¹ çš„æˆ‘æ¯å¤©è¿‡çš„å¾ˆæ„‰å¿«å“¦ğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Šï¼