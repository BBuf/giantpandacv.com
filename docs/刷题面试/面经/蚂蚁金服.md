1. 简单地介绍一下你自己
xxxxxx
2. 介绍一下你在图像隐写检测大赛复现这三篇论文里面的卷积神经网络的区别

Xunet是最早提出来用于隐写检测的卷积网络，在网络中加入abs绝对值层，TLU层。在图像预处理中使用了高通滤波器，帮助整个网络更快收敛
下图是高通滤波器
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200323100702893.png)
下图是低通滤波器
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200323100737719.png)
YeNet引入一个概率图模型，进行先验特征计算，最后用elementwise的方式加到第一个卷积层后的特征图，继续后续的卷积操作】
前两种网络都是针对灰度图的，而SRNet则是针对RGB图片，先对RGB这三个通道分离开，分别进入到相同的网络结构，进行卷积，最后在特征维上连结，通过一个全连接层输出概率

2. 讲一下你AI识虫目标检测这个项目
这个项目总的来说还是基于Yolov3进行调参，我先根据标签给的锚框大小进行了一次Kmeans聚类，调整了锚框大小。然后加入图像增广，比如左右翻移，随机缩放，随机改变亮度，对比度。整体网络结构没做过多改动，只是加入了SEBlock。训练策略加入了warmup，cos学习率衰减，标签平滑策略，最终提高了十几个点的map

3. 最后这个比赛是排名多少呢？总体的情况大概是怎样的？
排名是38，总参赛人数是342。总的来说这次比赛数据集给的问题较大，有些人有这样一种情况是训练集map是60，但是eval和test集合都达到了双百。后面他们就是完全基于eval集来训练，因此效果普遍比较好

4. 嗯也就是说比赛数据集给的有偏差，那么你平时会怎么去解决过拟合这个问题？
常见的就是在网络里面加dropout，另外我还会引入图像增广，正则化惩罚系数，模型融合，通过多个模型以投票机制进行打分

5. 在整个比赛里面你做的那么多操作中，你觉得提升Map最大的操作是哪一个
我觉得是图像增广，随机裁剪缩放都能很好地提升网络多尺度检测和泛化的性能。

6. 常规的机器学习算法有了解吗
这个之前学的也比较久了，大部分都忘了
（面试官补充说这方面知识后续也要补一补）

7. 我看你简历最后也加了个偏开发的项目，能稍微讲一讲吗
这是个京东移动端的爬虫项目，简单来说就是让手机和电脑处在同一个局域网内，电脑抓取手机的数据包，最后再一层层解开，以json格式存入MongoDB当中

8. 我看你也写了掌握那么多深度学习框架，能跟我讲讲区别是什么，你平时大概什么情况下用什么框架？
我初学的时候用的Keras，因为里面封装的清晰，最后能打印整个网络的张量运算图，有助于我理解和排查网络中的bug
当自定义操作较多的话我优先选择pytorch和mxnet，这两种基于动态图的框架在自定义方面较为简单
打比赛做项目我用的就是paddle飞桨框架，因为百度官网有免费算力可以使用（这一段我真的很耿直，能白嫖算力就白嫖）

 9. 你做了那么多项目，能跟我讲讲你做项目的流程吗，或者说项目中哪几个部分你比较看重？
 做项目的时候我优先会看整体数据分布情况，比如这次deepfake比赛中真假视频比例大概是4比1，我就会在网络的reader里面加入一次采样，维持样本平衡。另外就是阅读导师给的论文，了解有什么方法能处理这类的问题。对于骨干网络结构我不会过多关注，因为现在SOTA结构那么多，选个又快又准又小的就可以了。最后还是根据数据特性加入一定的图像增广来提升泛化性能，不同任务我的图像增广策略也不一样

9. 你项目中使用EfficientNet最后输出特征数是多少呢？
（这个当时是真忘了，有好几个版本，记得有点混）具体不记得了，但我用的是EfficientNet B0的结构（准确来说B0结构最后特征数是1280）

10. 能讲一下LSTM这几个门的结构吗
（这个也没答上来，直接跟面试官坦言RNN这方面研究没那么多）
整个LSTM包括三个门：输入门，遗忘门，输出门，另外还引入了一个记忆细胞
隐藏状态ht-1， 输入Xt
遗忘门主要是控制是否遗忘记忆细胞，这里是通过ht-1 和 xt经过一个权重运算，通过sigmoid激活输出的概率来代表记忆细胞遗忘概率

输入门由两部分组成，第一部分使用sigmoid函数，第二部分使用tanh函数，两者相乘，最后与记忆细胞相加，更新细胞状态

输出门，最后隐藏状态ht由两部分组成，一个是ht-1和xt运算经过sigmoid输出
另外一个是记忆细胞ct-1经过tanh运算，然后通过elementwise相乘，得到新的ht隐藏状态

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200323111106422.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDEwNjkyOA==,size_16,color_FFFFFF,t_70)
11. 对Loss损失函数有什么额外的了解吗
（这个也是一时紧张没说出来，以前做风格迁移和图像修复还是知道其他几个损失）

对抗损失，用于GAN中判别器和生成器之间的博弈得到的损失

感知损失，常用的均方损失对细节恢复的并不是很好，修复完的图像在细节特征抽取应该与原图一致，所以我们可以通过预训练好的VGG网络中的某几层进行抽取，最后通过L1来计算损失

样式损失，常用于风格迁移，灵感来源于感知损失，也是通过预训练好的网络中的某几层进行特征抽取，然后对（C, H, W）向量reshape成(C, H*W)的向量，通过gram格拉姆矩阵X XT，计算通道直接的特征相关性，最后再取个均方值

总变差损失，total variation loss，避免合成图像中大量的高频噪点，计算loss
Σ|X(i,j) - X(i+1, j)| + |X(i, j) - X(i, j+1)|

# 总结
电话面试还是有点紧张的，但整体面试过程很舒服，面试官不会刻意刁难你，针对你项目某个点会问的非常仔细，希望在这个难上加难的2020大家都能如愿拿到Offer~